{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nl2tU6kL8Ot3"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.sparse import csc_matrix\n",
        "\n",
        "\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4A9uU1WloQ2"
      },
      "source": [
        "# Data Loader Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cq3KEUaVo1o3"
      },
      "outputs": [],
      "source": [
        "def load_data_100k(path='./', delimiter='\\t'):\n",
        "\n",
        "    # ORIGINAL\n",
        "    # train = np.loadtxt(path+'movielens_100k_u1.base', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    # test = np.loadtxt(path+'movielens_100k_u1.test', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    # total = np.concatenate((train, test), axis=0)\n",
        "\n",
        "    # NEW\n",
        "    total = np.loadtxt(path+'u.data', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    mask = np.random.rand(len(total)) < 0.9\n",
        "    train = total[mask]\n",
        "    test = total[~mask]\n",
        "\n",
        "\n",
        "    n_u = np.unique(total[:,0]).size  # num of users\n",
        "    n_m = np.unique(total[:,1]).size  # num of movies\n",
        "    n_train = train.shape[0]  # num of training ratings\n",
        "    n_test = test.shape[0]  # num of test ratings\n",
        "\n",
        "    train_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "    test_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "\n",
        "    for i in range(n_train):\n",
        "        train_r[train[i,1]-1, train[i,0]-1] = train[i,2]\n",
        "\n",
        "    for i in range(n_test):\n",
        "        test_r[test[i,1]-1, test[i,0]-1] = test[i,2]\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_train))\n",
        "    print('num of test ratings: {}'.format(n_test))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "P3e8Xg3us8g7"
      },
      "outputs": [],
      "source": [
        "def load_data_1m(path='./', delimiter='::', frac=0.1, seed=1234):\n",
        "\n",
        "    tic = time()\n",
        "    print('reading data...')\n",
        "    data = np.loadtxt(path+'ratings.dat', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    print('taken', time() - tic, 'seconds')\n",
        "\n",
        "    n_u = np.unique(data[:,0]).size  # num of users\n",
        "    n_m = np.unique(data[:,1]).size  # num of movies\n",
        "    n_r = data.shape[0]  # num of ratings\n",
        "\n",
        "    udict = {}\n",
        "    for i, u in enumerate(np.unique(data[:,0]).tolist()):\n",
        "        udict[u] = i\n",
        "    mdict = {}\n",
        "    for i, m in enumerate(np.unique(data[:,1]).tolist()):\n",
        "        mdict[m] = i\n",
        "\n",
        "    # np.random.seed(seed)\n",
        "    idx = np.arange(n_r)\n",
        "    np.random.shuffle(idx)\n",
        "\n",
        "    train_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "    test_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "\n",
        "    for i in range(n_r):\n",
        "        u_id = data[idx[i], 0]\n",
        "        m_id = data[idx[i], 1]\n",
        "        r = data[idx[i], 2]\n",
        "\n",
        "        if i < int(frac * n_r):\n",
        "            test_r[mdict[m_id], udict[u_id]] = r\n",
        "        else:\n",
        "            train_r[mdict[m_id], udict[u_id]] = r\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_r - int(frac * n_r)))\n",
        "    print('num of test ratings: {}'.format(int(frac * n_r)))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "def load_data_tripadvisor(path='./', frac=0.1, seed=1234):\n",
        "\n",
        "    tic = time()\n",
        "    print('reading data...')\n",
        "    # Load reviews.pkl\n",
        "\n",
        "\n",
        "    \n",
        "    df = pd.read_pickle(path+ \"reviews.pkl\")\n",
        "\n",
        "    print(\"b\")\n",
        "    df = df[[\"userId\", \"restaurantId\", \"rating\"]]\n",
        "    df.columns = [\"user_id\", \"item_id\", \"rating\"]\n",
        "\n",
        "    print(\"c\")\n",
        "    # Drop items with less than 100 ratings and users with less than 20 ratings\n",
        "    # Remove repeated user-item pairs\n",
        "    df = df.drop_duplicates(subset=[\"user_id\", \"item_id\"], keep=\"first\")\n",
        "\n",
        "    # Create new user and item ids ( userId's are strings, restaurantId's are not continuous)\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(\"category\").cat.codes\n",
        "    df[\"item_id\"] = df[\"item_id\"].astype(\"category\").cat.codes\n",
        "\n",
        "    # Remove items with less than 10 ratings\n",
        "    postsPerItem = df.groupby(['item_id']).size()\n",
        "    df = df[np.in1d(df.item_id, postsPerItem[postsPerItem >= 10].index)]\n",
        "\n",
        "    # Remove users with less than 10 ratings\n",
        "    postsPerUser = df.groupby(['user_id']).size()\n",
        "    df = df[np.in1d(df.user_id, postsPerUser[postsPerUser >= 10].index)]\n",
        "\n",
        "    print(\"e\")\n",
        "\n",
        "    # Remove NA values\n",
        "    df = df.dropna()\n",
        "\n",
        "    print(\"f\")\n",
        "    # Create new user and item ids ( userId's are strings, restaurantId's are not continuous)\n",
        "    df[\"user_id\"] = df[\"user_id\"].astype(\"category\").cat.codes\n",
        "    df[\"item_id\"] = df[\"item_id\"].astype(\"category\").cat.codes\n",
        "\n",
        "    print(\"g\")\n",
        "\n",
        "    df[\"rating\"] = df[\"rating\"] / 10\n",
        "\n",
        "    print(\"h\")\n",
        "\n",
        "    data = df.values\n",
        "\n",
        "    print('taken', time() - tic, 'seconds')\n",
        "\n",
        "    print(\"Constructing data matrix...\")\n",
        "    n_u = np.unique(data[:,0]).size  # num of users\n",
        "    n_m = np.unique(data[:,1]).size  # num of movies\n",
        "    n_r = data.shape[0]  # num of ratings\n",
        "\n",
        "    udict = {}\n",
        "    for i, u in enumerate(np.unique(data[:,0]).tolist()):\n",
        "        udict[u] = i\n",
        "    mdict = {}\n",
        "    for i, m in enumerate(np.unique(data[:,1]).tolist()):\n",
        "        mdict[m] = i\n",
        "\n",
        "    # np.random.seed(seed)\n",
        "    idx = np.arange(n_r)\n",
        "    np.random.shuffle(idx)\n",
        "\n",
        "    train_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "    test_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "\n",
        "    for i in range(n_r):\n",
        "        u_id = data[idx[i], 0]\n",
        "        m_id = data[idx[i], 1]\n",
        "        r = data[idx[i], 2]\n",
        "\n",
        "        if i < int(frac * n_r):\n",
        "            test_r[mdict[m_id], udict[u_id]] = r\n",
        "        else:\n",
        "            train_r[mdict[m_id], udict[u_id]] = r\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_r - int(frac * n_r)))\n",
        "    print('num of test ratings: {}'.format(int(frac * n_r)))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7rMjcbLvhtRs"
      },
      "outputs": [],
      "source": [
        "def load_matlab_file(path_file, name_field):\n",
        "    \n",
        "    db = h5py.File(path_file, 'r')\n",
        "    ds = db[name_field]\n",
        "\n",
        "    try:\n",
        "        if 'ir' in ds.keys():\n",
        "            data = np.asarray(ds['data'])\n",
        "            ir   = np.asarray(ds['ir'])\n",
        "            jc   = np.asarray(ds['jc'])\n",
        "            out  = csc_matrix((data, ir, jc)).astype(np.float32)\n",
        "    except AttributeError:\n",
        "        out = np.asarray(ds).astype(np.float32).T\n",
        "\n",
        "    db.close()\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "g6pIUrkza2zv"
      },
      "outputs": [],
      "source": [
        "def load_data_monti(path='./'):\n",
        "\n",
        "    M = load_matlab_file(path+'training_test_dataset.mat', 'M')\n",
        "    Otraining = load_matlab_file(path+'training_test_dataset.mat', 'Otraining') * M\n",
        "    Otest = load_matlab_file(path+'training_test_dataset.mat', 'Otest') * M\n",
        "\n",
        "    n_u = M.shape[0]  # num of users\n",
        "    n_m = M.shape[1]  # num of movies\n",
        "    n_train = Otraining[np.where(Otraining)].size  # num of training ratings\n",
        "    n_test = Otest[np.where(Otest)].size  # num of test ratings\n",
        "\n",
        "    train_r = Otraining.T\n",
        "    test_r = Otest.T\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_train))\n",
        "    print('num of test ratings: {}'.format(n_test))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_8kEkg9mlIW"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0fkA1WpmipzF"
      },
      "outputs": [],
      "source": [
        "# Insert the path of a data directory by yourself (e.g., '/content/.../data')\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
        "data_path = '../../data'\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ijlu0lXQioYM"
      },
      "outputs": [],
      "source": [
        "# Select a dataset among 'ML-1M', 'ML-100K', and 'Douban'\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
        "dataset = 'tripadvisor'\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sJqSSY33mgkw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading data...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b\n",
            "c\n",
            "e\n",
            "f\n",
            "g\n",
            "h\n",
            "taken 11.133225440979004 seconds\n",
            "Constructing data matrix...\n",
            "data matrix loaded\n",
            "num of users: 25388\n",
            "num of movies: 12384\n",
            "num of training ratings: 442053\n",
            "num of test ratings: 49117\n"
          ]
        }
      ],
      "source": [
        "# Data Load\n",
        "try:\n",
        "    if dataset == 'ML-100K':\n",
        "        path = data_path + '/ml-100k/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_100k(path=path, delimiter='\\t')\n",
        "\n",
        "    elif dataset == 'ML-1M':\n",
        "        path = data_path + '/ml-1m/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_1m(path=path, delimiter='::', frac=0.1, seed=1234)\n",
        "\n",
        "    elif dataset == 'ML-10M':\n",
        "        path = data_path + '/ml-10m/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_1m(path=path, delimiter='::', frac=0.1, seed=1234)\n",
        "\n",
        "    elif dataset == 'Douban':\n",
        "        path = data_path + '/douban-monti/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_monti(path=path)\n",
        "\n",
        "    elif dataset == 'tripadvisor':\n",
        "        path = data_path + '/tripadvisor-london/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_tripadvisor(path=path)\n",
        "\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "except ValueError:\n",
        "    print('Error: Unable to load data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQMtA9yml-gp"
      },
      "source": [
        "# Hyperparameter Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nGCdp_FlobOK"
      },
      "outputs": [],
      "source": [
        "# Common hyperparameter settings\n",
        "n_hid = 500\n",
        "n_dim = 5\n",
        "n_layers = 2\n",
        "gk_size = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "344bwGB0cWXp"
      },
      "outputs": [],
      "source": [
        "# Different hyperparameter settings for each dataset\n",
        "if dataset == 'ML-100K' or dataset == 'tripadvisor':\n",
        "    lambda_2 = 20.  # l2 regularisation\n",
        "    lambda_s = 0.006\n",
        "    iter_p = 5  # optimisation\n",
        "    iter_f = 5\n",
        "    epoch_p = 30  # training epoch\n",
        "    epoch_f = 60\n",
        "    dot_scale = 1  # scaled dot product\n",
        "\n",
        "elif dataset == 'ML-1M':\n",
        "    lambda_2 = 70.\n",
        "    lambda_s = 0.018\n",
        "    iter_p = 50\n",
        "    iter_f = 10\n",
        "    epoch_p = 20\n",
        "    epoch_f = 30\n",
        "    dot_scale = 0.5\n",
        "\n",
        "elif dataset == 'Douban':\n",
        "    lambda_2 = 10.\n",
        "    lambda_s = 0.022\n",
        "    iter_p = 5\n",
        "    iter_f = 5\n",
        "    epoch_p = 20\n",
        "    epoch_f = 60\n",
        "    dot_scale = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Disable GPU\n",
        "tf.compat.v1.config.experimental.set_visible_devices([], 'GPU')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "b94aimX3nAMI"
      },
      "outputs": [],
      "source": [
        "R = tf.placeholder(\"float\", [n_m, n_u])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sWtU4-pmDDT"
      },
      "source": [
        "# Network Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wX2wREO09zde"
      },
      "outputs": [],
      "source": [
        "def local_kernel(u, v):\n",
        "\n",
        "    dist = tf.norm(u - v, ord=2, axis=2)\n",
        "    hat = tf.maximum(0., 1. - dist**2)\n",
        "\n",
        "    return hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "c88l9LYr9175"
      },
      "outputs": [],
      "source": [
        "def kernel_layer(x, n_hid=n_hid, n_dim=n_dim, activation=tf.nn.sigmoid, lambda_s=lambda_s, lambda_2=lambda_2, name=''):\n",
        "\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        W = tf.get_variable('W', [x.shape[1], n_hid])\n",
        "        n_in = x.get_shape().as_list()[1]\n",
        "        u = tf.get_variable('u', initializer=tf.random.truncated_normal([n_in, 1, n_dim], 0., 1e-3))\n",
        "        v = tf.get_variable('v', initializer=tf.random.truncated_normal([1, n_hid, n_dim], 0., 1e-3))\n",
        "        b = tf.get_variable('b', [n_hid])\n",
        "\n",
        "    w_hat = local_kernel(u, v)\n",
        "    \n",
        "    sparse_reg = tf.contrib.layers.l2_regularizer(lambda_s)\n",
        "    sparse_reg_term = tf.contrib.layers.apply_regularization(sparse_reg, [w_hat])\n",
        "    \n",
        "    l2_reg = tf.contrib.layers.l2_regularizer(lambda_2)\n",
        "    l2_reg_term = tf.contrib.layers.apply_regularization(l2_reg, [W])\n",
        "\n",
        "    W_eff = W * w_hat  # Local kernelised weight matrix\n",
        "    y = tf.matmul(x, W_eff) + b\n",
        "    y = activation(y)\n",
        "\n",
        "    return y, sparse_reg_term + l2_reg_term"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rlb95FmRVATa"
      },
      "outputs": [],
      "source": [
        "def global_kernel(input, gk_size, dot_scale):\n",
        "\n",
        "    avg_pooling = tf.reduce_mean(input, axis=1)  # Item (axis=1) based average pooling\n",
        "    avg_pooling = tf.reshape(avg_pooling, [1, -1])\n",
        "    n_kernel = avg_pooling.shape[1].value\n",
        "\n",
        "    conv_kernel = tf.get_variable('conv_kernel', initializer=tf.random.truncated_normal([n_kernel, gk_size**2], stddev=0.1))\n",
        "    gk = tf.matmul(avg_pooling, conv_kernel) * dot_scale  # Scaled dot product\n",
        "    gk = tf.reshape(gk, [gk_size, gk_size, 1, 1])\n",
        "\n",
        "    return gk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jTLi_65XzIbH"
      },
      "outputs": [],
      "source": [
        "def global_conv(input, W):\n",
        "\n",
        "    input = tf.reshape(input, [1, input.shape[0], input.shape[1], 1])\n",
        "    conv2d = tf.nn.relu(tf.nn.conv2d(input, W, strides=[1,1,1,1], padding='SAME'))\n",
        "\n",
        "    return tf.reshape(conv2d, [conv2d.shape[1], conv2d.shape[2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8sQCwrSmKG4"
      },
      "source": [
        "# Network Instantiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOtWj1SCo1RW"
      },
      "source": [
        "## Pre-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7teUrgWagpW0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Komi\\Papers\\SUB-COFI\\venv_GLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": [
        "y = R\n",
        "reg_losses = None\n",
        "\n",
        "for i in range(n_layers):\n",
        "    y, reg_loss = kernel_layer(y, name=str(i))\n",
        "    reg_losses = reg_loss if reg_losses is None else reg_losses + reg_loss\n",
        "\n",
        "pred_p, reg_loss = kernel_layer(y, n_u, activation=tf.identity, name='out')\n",
        "reg_losses = reg_losses + reg_loss\n",
        "\n",
        "# L2 loss\n",
        "diff = train_m * (train_r - pred_p)\n",
        "sqE = tf.nn.l2_loss(diff)\n",
        "loss_p = sqE + reg_losses\n",
        "\n",
        "optimizer_p = tf.contrib.opt.ScipyOptimizerInterface(loss_p, options={'disp': True, 'maxiter': iter_p, 'maxcor': 10}, method='L-BFGS-B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IEBsNhNo4Cj"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "OiTXqnN6zLXQ"
      },
      "outputs": [],
      "source": [
        "y = R\n",
        "reg_losses = None\n",
        "\n",
        "for i in range(n_layers):\n",
        "    y, _ = kernel_layer(y, name=str(i))\n",
        "\n",
        "y_dash, _ = kernel_layer(y, n_u, activation=tf.identity, name='out')\n",
        "\n",
        "gk = global_kernel(y_dash, gk_size, dot_scale)  # Global kernel\n",
        "y_hat = global_conv(train_r, gk)  # Global kernel-based rating matrix\n",
        "\n",
        "for i in range(n_layers):\n",
        "    y_hat, reg_loss = kernel_layer(y_hat, name=str(i))\n",
        "    reg_losses = reg_loss if reg_losses is None else reg_losses + reg_loss\n",
        "\n",
        "pred_f, reg_loss = kernel_layer(y_hat, n_u, activation=tf.identity, name='out')\n",
        "reg_losses = reg_losses + reg_loss\n",
        "\n",
        "# L2 loss\n",
        "diff = train_m * (train_r - pred_f)\n",
        "sqE = tf.nn.l2_loss(diff)\n",
        "loss_f = sqE + reg_losses\n",
        "\n",
        "optimizer_f = tf.contrib.opt.ScipyOptimizerInterface(loss_f, options={'disp': True, 'maxiter': iter_f, 'maxcor': 10}, method='L-BFGS-B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sETwz58aK6y6"
      },
      "source": [
        "# Evaluation code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vyReXxgac3KH"
      },
      "outputs": [],
      "source": [
        "def dcg_k(score_label, k):\n",
        "    dcg, i = 0., 0\n",
        "    for s in score_label:\n",
        "        if i < k:\n",
        "            dcg += (2**s[1]-1) / np.log2(2+i)\n",
        "            i += 1\n",
        "    return dcg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jwsSR-8ZdGWo"
      },
      "outputs": [],
      "source": [
        "def ndcg_k(y_hat, y, k):\n",
        "    score_label = np.stack([y_hat, y], axis=1).tolist()\n",
        "    score_label = sorted(score_label, key=lambda d:d[0], reverse=True)\n",
        "    score_label_ = sorted(score_label, key=lambda d:d[1], reverse=True)\n",
        "    norm, i = 0., 0\n",
        "    for s in score_label_:\n",
        "        if i < k:\n",
        "            norm += (2**s[1]-1) / np.log2(2+i)\n",
        "            i += 1\n",
        "    dcg = dcg_k(score_label, k)\n",
        "    return dcg / norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "yy9eQS51pbhj"
      },
      "outputs": [],
      "source": [
        "def call_ndcg(y_hat, y):\n",
        "    ndcg_sum, num = 0, 0\n",
        "    y_hat, y = y_hat.T, y.T\n",
        "    n_users = y.shape[0]\n",
        "\n",
        "    for i in range(n_users):\n",
        "        y_hat_i = y_hat[i][np.where(y[i])]\n",
        "        y_i = y[i][np.where(y[i])]\n",
        "\n",
        "        if y_i.shape[0] < 2:\n",
        "            continue\n",
        "\n",
        "        ndcg_sum += ndcg_k(y_hat_i, y_i, y_i.shape[0])  # user-wise calculation\n",
        "        num += 1\n",
        "\n",
        "    return ndcg_sum / num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXXQjeMxmYEC"
      },
      "source": [
        "# Training and Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtain the train and test samples in a Pandas DataFrame\n",
        "# with format user_id (int), movie_id (int), rating (float)\n",
        "# and save them as CSV files\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def extract_test_samples(rating_matrix, mask_matrix):\n",
        "    test_samples = np.where(mask_matrix > 0)\n",
        "    test_samples = np.stack([test_samples[1], test_samples[0]], axis=1)\n",
        "    test_samples = pd.DataFrame(test_samples, columns=['user_id', 'movie_id'])\n",
        "    test_samples['rating'] = rating_matrix[test_samples['movie_id'], test_samples['user_id']]\n",
        "\n",
        "    return test_samples\n",
        "\n",
        "train_samples = extract_test_samples(train_r, train_m)\n",
        "test_samples = extract_test_samples(test_r, test_m)\n",
        "\n",
        "OUTPUTS_PATH = '../../outputs/'\n",
        "MODEL_NAME = 'GLOCAL_K'\n",
        "\n",
        "# Make sure that the directory exists\n",
        "import os\n",
        "os.makedirs(OUTPUTS_PATH + MODEL_NAME, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UZ35Zoha-Eue"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: True\n",
            "GPU device: /device:GPU:0\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 1118146.750000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 8\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 1 test rmse: 2.1272044 train rmse: 2.029353\n",
            "Time: 221.14702320098877 seconds\n",
            "Time cumulative: 221.14702320098877 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 425324.625000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 6\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 2 test rmse: 1.2853974 train rmse: 1.1815212\n",
            "Time: 64.39505791664124 seconds\n",
            "Time cumulative: 285.54208111763 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 330827.500000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 6\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 3 test rmse: 1.0463191 train rmse: 0.9739891\n",
            "Time: 62.828359603881836 seconds\n",
            "Time cumulative: 348.37044072151184 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 305129.562500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 4 test rmse: 1.0061142 train rmse: 0.93831223\n",
            "Time: 66.50908303260803 seconds\n",
            "Time cumulative: 414.8795237541199 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 303131.156250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 5 test rmse: 0.99783987 train rmse: 0.9338889\n",
            "Time: 66.96058106422424 seconds\n",
            "Time cumulative: 481.8401048183441 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 302380.156250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 6 test rmse: 0.99568415 train rmse: 0.9323752\n",
            "Time: 66.58621835708618 seconds\n",
            "Time cumulative: 548.4263231754303 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 301663.750000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 7 test rmse: 0.9943761 train rmse: 0.9315086\n",
            "Time: 67.37755370140076 seconds\n",
            "Time cumulative: 615.803876876831 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 300825.125000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 8 test rmse: 0.99306417 train rmse: 0.9299611\n",
            "Time: 65.77081489562988 seconds\n",
            "Time cumulative: 681.5746917724609 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 300083.031250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 9 test rmse: 0.99159133 train rmse: 0.9288162\n",
            "Time: 64.23402571678162 seconds\n",
            "Time cumulative: 745.8087174892426 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 299315.781250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 10 test rmse: 0.99031657 train rmse: 0.9272579\n",
            "Time: 64.69086718559265 seconds\n",
            "Time cumulative: 810.4995846748352 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 297991.062500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 8\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 11 test rmse: 0.9877017 train rmse: 0.92514324\n",
            "Time: 71.53626823425293 seconds\n",
            "Time cumulative: 882.0358529090881 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 296917.906250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 12 test rmse: 0.9858891 train rmse: 0.92273396\n",
            "Time: 69.17664217948914 seconds\n",
            "Time cumulative: 951.2124950885773 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 296314.812500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 13 test rmse: 0.9846982 train rmse: 0.9217523\n",
            "Time: 67.89927268028259 seconds\n",
            "Time cumulative: 1019.1117677688599 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 295327.593750\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 14 test rmse: 0.9833218 train rmse: 0.9198471\n",
            "Time: 66.274329662323 seconds\n",
            "Time cumulative: 1085.3860974311829 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 294585.625000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 15 test rmse: 0.9817539 train rmse: 0.9184856\n",
            "Time: 66.87588047981262 seconds\n",
            "Time cumulative: 1152.2619779109955 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 293842.125000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 16 test rmse: 0.98069304 train rmse: 0.917139\n",
            "Time: 68.60381126403809 seconds\n",
            "Time cumulative: 1220.8657891750336 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 293232.750000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 17 test rmse: 0.9794523 train rmse: 0.9159926\n",
            "Time: 69.41242933273315 seconds\n",
            "Time cumulative: 1290.2782185077667 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 292481.125000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 18 test rmse: 0.9786486 train rmse: 0.9147974\n",
            "Time: 68.05026435852051 seconds\n",
            "Time cumulative: 1358.3284828662872 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 291735.500000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 19 test rmse: 0.9770159 train rmse: 0.91329795\n",
            "Time: 66.55076336860657 seconds\n",
            "Time cumulative: 1424.8792462348938 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 291091.687500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 20 test rmse: 0.9761062 train rmse: 0.91231704\n",
            "Time: 64.72791194915771 seconds\n",
            "Time cumulative: 1489.6071581840515 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 290484.562500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 21 test rmse: 0.9750279 train rmse: 0.9111398\n",
            "Time: 66.23559832572937 seconds\n",
            "Time cumulative: 1555.8427565097809 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 289788.312500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 22 test rmse: 0.97422403 train rmse: 0.9100955\n",
            "Time: 67.37777066230774 seconds\n",
            "Time cumulative: 1623.2205271720886 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 289209.656250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 23 test rmse: 0.9731933 train rmse: 0.90898\n",
            "Time: 65.87489008903503 seconds\n",
            "Time cumulative: 1689.0954172611237 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 288480.031250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 24 test rmse: 0.9724764 train rmse: 0.90795845\n",
            "Time: 64.28868246078491 seconds\n",
            "Time cumulative: 1753.3840997219086 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 287873.781250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 25 test rmse: 0.97150356 train rmse: 0.90682036\n",
            "Time: 65.32228922843933 seconds\n",
            "Time cumulative: 1818.706388950348 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 287450.250000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 26 test rmse: 0.97104186 train rmse: 0.9061377\n",
            "Time: 67.07698726654053 seconds\n",
            "Time cumulative: 1885.7833762168884 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 287057.093750\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 27 test rmse: 0.9704226 train rmse: 0.9054978\n",
            "Time: 67.79898309707642 seconds\n",
            "Time cumulative: 1953.5823593139648 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 286186.250000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 28 test rmse: 0.96976364 train rmse: 0.9043125\n",
            "Time: 66.29829359054565 seconds\n",
            "Time cumulative: 2019.8806529045105 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 285604.031250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 29 test rmse: 0.96880317 train rmse: 0.90320957\n",
            "Time: 64.75214338302612 seconds\n",
            "Time cumulative: 2084.6327962875366 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 284821.687500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 30 test rmse: 0.9682703 train rmse: 0.9021122\n",
            "Time: 65.4508376121521 seconds\n",
            "Time cumulative: 2150.0836338996887 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 298583.468750\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.9982949\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 1 test rmse: 0.9982949 test mae: 0.7671749 test ndcg: 0.9253465075088353\n",
            "Epoch: 1 train rmse: 0.936612 train mae: 0.72175705 train ndcg: 0.8784370295364634\n",
            "Time: 441.3420157432556 seconds\n",
            "Time cumulative: 2591.4256496429443 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 287989.968750\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 6\n",
            "New best test rmse: 0.97844994\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 2 test rmse: 0.97844994 test mae: 0.74951565 test ndcg: 0.9338940099798317\n",
            "Epoch: 2 train rmse: 0.9109733 train mae: 0.6988335 train ndcg: 0.8941687497620474\n",
            "Time: 192.60984301567078 seconds\n",
            "Time cumulative: 2784.035492658615 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 283517.562500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.9697767\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 3 test rmse: 0.9697767 test mae: 0.7436234 test ndcg: 0.9379202610483274\n",
            "Epoch: 3 train rmse: 0.89990926 train mae: 0.6910654 train ndcg: 0.9020346416183928\n",
            "Time: 218.2355215549469 seconds\n",
            "Time cumulative: 3002.271014213562 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 281335.437500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 8\n",
            "New best test rmse: 0.96607697\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 4 test rmse: 0.96607697 test mae: 0.7402724 test ndcg: 0.9392941315634035\n",
            "Epoch: 4 train rmse: 0.89450127 train mae: 0.6862628 train ndcg: 0.9044426891139141\n",
            "Time: 235.70307970046997 seconds\n",
            "Time cumulative: 3237.974093914032 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 279646.750000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.9632981\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 5 test rmse: 0.9632981 test mae: 0.73948365 test ndcg: 0.9397361601221914\n",
            "Epoch: 5 train rmse: 0.8905308 train mae: 0.6846895 train ndcg: 0.9059966446342737\n",
            "Time: 212.46548080444336 seconds\n",
            "Time cumulative: 3450.4395747184753 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 279081.656250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 8\n",
            "New best test rmse: 0.9622558\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 6 test rmse: 0.9622558 test mae: 0.73804384 test ndcg: 0.9399493342293292\n",
            "Epoch: 6 train rmse: 0.88911545 train mae: 0.6829698 train ndcg: 0.9065423651135682\n",
            "Time: 238.76574897766113 seconds\n",
            "Time cumulative: 3689.2053236961365 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 278457.781250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 8\n",
            "New best test rmse: 0.9614458\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 7 test rmse: 0.9614458 test mae: 0.73762774 test ndcg: 0.9402884004499895\n",
            "Epoch: 7 train rmse: 0.88761276 train mae: 0.68192226 train ndcg: 0.9072607500494388\n",
            "Time: 232.0670359134674 seconds\n",
            "Time cumulative: 3921.272359609604 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 277718.781250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.96047854\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 8 test rmse: 0.96047854 test mae: 0.7368752 test ndcg: 0.9405202111422684\n",
            "Epoch: 8 train rmse: 0.88585263 train mae: 0.6804942 train ndcg: 0.9079258243726348\n",
            "Time: 209.40995264053345 seconds\n",
            "Time cumulative: 4130.682312250137 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 276702.500000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.959348\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 9 test rmse: 0.959348 test mae: 0.73620236 test ndcg: 0.9406786072583203\n",
            "Epoch: 9 train rmse: 0.88351804 train mae: 0.6788685 train ndcg: 0.9087129181088857\n",
            "Time: 208.80786442756653 seconds\n",
            "Time cumulative: 4339.490176677704 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 276144.500000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.9586716\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 10 test rmse: 0.9586716 test mae: 0.7354472 test ndcg: 0.9409346076215007\n",
            "Epoch: 10 train rmse: 0.8821968 train mae: 0.6776136 train ndcg: 0.9091958251814645\n",
            "Time: 207.76808953285217 seconds\n",
            "Time cumulative: 4547.258266210556 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 275306.312500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.9578898\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 11 test rmse: 0.9578898 test mae: 0.7350143 test ndcg: 0.9409221152967535\n",
            "Epoch: 11 train rmse: 0.88030475 train mae: 0.67623264 train ndcg: 0.9096422559004073\n",
            "Time: 207.4299488067627 seconds\n",
            "Time cumulative: 4754.688215017319 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 274742.531250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.95743924\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 12 test rmse: 0.95743924 test mae: 0.73438215 test ndcg: 0.9409105373198438\n",
            "Epoch: 12 train rmse: 0.8790209 train mae: 0.6749776 train ndcg: 0.9099640231877684\n",
            "Time: 206.38069701194763 seconds\n",
            "Time cumulative: 4961.068912029266 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 273643.093750\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 8\n",
            "New best test rmse: 0.9571398\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 13 test rmse: 0.9571398 test mae: 0.73481506 test ndcg: 0.9409395138726148\n",
            "Epoch: 13 train rmse: 0.8768268 train mae: 0.6739245 train ndcg: 0.9102916644009954\n",
            "Time: 230.8188214302063 seconds\n",
            "Time cumulative: 5191.887733459473 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 272914.937500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.9561494\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 14 test rmse: 0.9561494 test mae: 0.7328422 test ndcg: 0.9409908970016836\n",
            "Epoch: 14 train rmse: 0.87503433 train mae: 0.67142415 train ndcg: 0.91073416986323\n",
            "Time: 205.49304223060608 seconds\n",
            "Time cumulative: 5397.380775690079 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 271789.531250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.95572644\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 15 test rmse: 0.95572644 test mae: 0.7327285 test ndcg: 0.9412450484851265\n",
            "Epoch: 15 train rmse: 0.87270665 train mae: 0.6697554 train ndcg: 0.9112358952455191\n",
            "Time: 212.729266166687 seconds\n",
            "Time cumulative: 5610.110041856766 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 271235.187500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.9551795\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 16 test rmse: 0.9551795 test mae: 0.7319453 test ndcg: 0.9413994365884466\n",
            "Epoch: 16 train rmse: 0.8714726 train mae: 0.668572 train ndcg: 0.9114873840649703\n",
            "Time: 211.317640542984 seconds\n",
            "Time cumulative: 5821.42768239975 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 269822.812500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 8\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 17 test rmse: 0.95658183 test mae: 0.7349076 test ndcg: 0.9416230967897263\n",
            "Epoch: 17 train rmse: 0.86917424 train mae: 0.6685559 train ndcg: 0.9117707151743678\n",
            "Time: 235.70094347000122 seconds\n",
            "Time cumulative: 6057.128625869751 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 268592.125000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.95416635\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 18 test rmse: 0.95416635 test mae: 0.7307994 test ndcg: 0.9414565430163985\n",
            "Epoch: 18 train rmse: 0.8661573 train mae: 0.66429615 train ndcg: 0.9122334554165623\n",
            "Time: 208.6116280555725 seconds\n",
            "Time cumulative: 6265.7402539253235 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 267625.593750\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 8\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 19 test rmse: 0.95447576 test mae: 0.73152125 test ndcg: 0.9417258407831872\n",
            "Epoch: 19 train rmse: 0.86443484 train mae: 0.6633976 train ndcg: 0.9124603282936732\n",
            "Time: 231.44976782798767 seconds\n",
            "Time cumulative: 6497.190021753311 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 266978.687500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.9538623\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 20 test rmse: 0.9538623 test mae: 0.7301882 test ndcg: 0.9415796374048083\n",
            "Epoch: 20 train rmse: 0.8630706 train mae: 0.6617086 train ndcg: 0.9127817819784784\n",
            "Time: 210.62467551231384 seconds\n",
            "Time cumulative: 6707.814697265625 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 266152.750000\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 8\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 21 test rmse: 0.955285 test mae: 0.7326592 test ndcg: 0.9414875505399692\n",
            "Epoch: 21 train rmse: 0.86203384 train mae: 0.6621095 train ndcg: 0.9129995471221712\n",
            "Time: 232.39249563217163 seconds\n",
            "Time cumulative: 6940.207192897797 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 265177.937500\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n",
            "New best test rmse: 0.95357686\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 22 test rmse: 0.95357686 test mae: 0.73008424 test ndcg: 0.9416944423959936\n",
            "Epoch: 22 train rmse: 0.8598077 train mae: 0.6593992 train ndcg: 0.9133493637009239\n",
            "Time: 212.64980220794678 seconds\n",
            "Time cumulative: 7152.856995105743 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 263077.281250\n",
            "  Number of iterations: 5\n",
            "  Number of functions evaluations: 7\n"
          ]
        }
      ],
      "source": [
        "best_rmse_ep, best_mae_ep, best_ndcg_ep = 0, 0, 0\n",
        "best_rmse, best_mae, best_ndcg = float(\"inf\"), float(\"inf\"), 0\n",
        "\n",
        "time_cumulative = 0\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Check GPU is available\n",
        "\n",
        "print('GPU available:', tf.test.is_gpu_available())\n",
        "print('GPU device:', tf.test.gpu_device_name())\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(epoch_p):\n",
        "        tic = time()\n",
        "        optimizer_p.minimize(sess, feed_dict={R: train_r})\n",
        "        pre = sess.run(pred_p, feed_dict={R: train_r})\n",
        "\n",
        "        t = time() - tic\n",
        "        time_cumulative += t\n",
        "        \n",
        "        error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n",
        "        test_rmse = np.sqrt(error)\n",
        "\n",
        "        error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n",
        "        train_rmse = np.sqrt(error_train)\n",
        "\n",
        "        print('.-^-._' * 12)\n",
        "        print('PRE-TRAINING')\n",
        "        print('Epoch:', i+1, 'test rmse:', test_rmse, 'train rmse:', train_rmse)\n",
        "        print('Time:', t, 'seconds')\n",
        "        print('Time cumulative:', time_cumulative, 'seconds')\n",
        "        print('.-^-._' * 12)\n",
        "\n",
        "    for i in range(epoch_f):\n",
        "        tic = time()\n",
        "        optimizer_f.minimize(sess, feed_dict={R: train_r})\n",
        "        pre = sess.run(pred_f, feed_dict={R: train_r})\n",
        "\n",
        "        t = time() - tic\n",
        "        time_cumulative += t\n",
        "        \n",
        "        error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n",
        "        test_rmse = np.sqrt(error)\n",
        "\n",
        "        error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n",
        "        train_rmse = np.sqrt(error_train)\n",
        "\n",
        "        test_mae = (test_m * np.abs(np.clip(pre, 1., 5.) - test_r)).sum() / test_m.sum()\n",
        "        train_mae = (train_m * np.abs(np.clip(pre, 1., 5.) - train_r)).sum() / train_m.sum()\n",
        "\n",
        "        test_ndcg = call_ndcg(np.clip(pre, 1., 5.), test_r)\n",
        "        train_ndcg = call_ndcg(np.clip(pre, 1., 5.), train_r)\n",
        "\n",
        "        if test_rmse < best_rmse:\n",
        "\n",
        "            best_rmse = test_rmse\n",
        "            best_rmse_ep = i+1\n",
        "            print(\"New best test rmse:\", best_rmse)\n",
        "\n",
        "            # Update predictions in the dataframe\n",
        "            test_samples['pred'] = np.clip(pre[test_samples['movie_id'], test_samples['user_id']], 1., 5.)\n",
        "            train_samples['pred'] = np.clip(pre[train_samples['movie_id'], train_samples['user_id']], 1., 5.)\n",
        "        \n",
        "        if test_mae < best_mae:\n",
        "            best_mae = test_mae\n",
        "            best_mae_ep = i+1\n",
        "\n",
        "        if best_ndcg < test_ndcg:\n",
        "            best_ndcg = test_ndcg\n",
        "            best_ndcg_ep = i+1\n",
        "\n",
        "        print('.-^-._' * 12)\n",
        "        print('FINE-TUNING')\n",
        "        print('Epoch:', i+1, 'test rmse:', test_rmse, 'test mae:', test_mae, 'test ndcg:', test_ndcg)\n",
        "        print('Epoch:', i+1, 'train rmse:', train_rmse, 'train mae:', train_mae, 'train ndcg:', train_ndcg)\n",
        "        print('Time:', t, 'seconds')\n",
        "        print('Time cumulative:', time_cumulative, 'seconds')\n",
        "        print('.-^-._' * 12)\n",
        "\n",
        "    print('Best test rmse:', best_rmse, 'at epoch', best_rmse_ep)\n",
        "\n",
        "    # Rename movie_id to item_id\n",
        "    train_samples = train_samples.rename(columns={'movie_id': 'item_id'})\n",
        "    test_samples = test_samples.rename(columns={'movie_id': 'item_id'})\n",
        "    # Save the predictions in a CSV file\n",
        "    train_samples.to_csv(OUTPUTS_PATH + MODEL_NAME + '/train_samples.csv', index=False)\n",
        "    test_samples.to_csv(OUTPUTS_PATH + MODEL_NAME + '/test_samples_with_predictions.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTi_PdXJqTjh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 30  best rmse: 0.9540589\n",
            "Epoch: 43  best mae: 0.72930425\n",
            "Epoch: 35  best ndcg: 0.9419117048187692\n"
          ]
        }
      ],
      "source": [
        "# Final result\n",
        "print('Epoch:', best_rmse_ep, ' best rmse:', best_rmse)\n",
        "print('Epoch:', best_mae_ep, ' best mae:', best_mae)\n",
        "print('Epoch:', best_ndcg_ep, ' best ndcg:', best_ndcg)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GLocal_K.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

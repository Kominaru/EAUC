{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "nl2tU6kL8Ot3"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.sparse import csc_matrix\n",
        "\n",
        "\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4A9uU1WloQ2"
      },
      "source": [
        "# Data Loader Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "cq3KEUaVo1o3"
      },
      "outputs": [],
      "source": [
        "def load_data_100k(path='./', delimiter='\\t'):\n",
        "\n",
        "    train = np.loadtxt(path+'movielens_100k_u1.base', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    test = np.loadtxt(path+'movielens_100k_u1.test', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    total = np.concatenate((train, test), axis=0)\n",
        "\n",
        "    n_u = np.unique(total[:,0]).size  # num of users\n",
        "    n_m = np.unique(total[:,1]).size  # num of movies\n",
        "    n_train = train.shape[0]  # num of training ratings\n",
        "    n_test = test.shape[0]  # num of test ratings\n",
        "\n",
        "    train_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "    test_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "\n",
        "    for i in range(n_train):\n",
        "        train_r[train[i,1]-1, train[i,0]-1] = train[i,2]\n",
        "\n",
        "    for i in range(n_test):\n",
        "        test_r[test[i,1]-1, test[i,0]-1] = test[i,2]\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_train))\n",
        "    print('num of test ratings: {}'.format(n_test))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "P3e8Xg3us8g7"
      },
      "outputs": [],
      "source": [
        "def load_data_1m(path='./', delimiter='::', frac=0.1, seed=1234):\n",
        "\n",
        "    tic = time()\n",
        "    print('reading data...')\n",
        "    data = np.loadtxt(path+'ratings.dat', skiprows=0, delimiter=delimiter).astype('int32')\n",
        "    print('taken', time() - tic, 'seconds')\n",
        "\n",
        "    n_u = np.unique(data[:,0]).size  # num of users\n",
        "    n_m = np.unique(data[:,1]).size  # num of movies\n",
        "    n_r = data.shape[0]  # num of ratings\n",
        "\n",
        "    udict = {}\n",
        "    for i, u in enumerate(np.unique(data[:,0]).tolist()):\n",
        "        udict[u] = i\n",
        "    mdict = {}\n",
        "    for i, m in enumerate(np.unique(data[:,1]).tolist()):\n",
        "        mdict[m] = i\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    idx = np.arange(n_r)\n",
        "    np.random.shuffle(idx)\n",
        "\n",
        "    train_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "    test_r = np.zeros((n_m, n_u), dtype='float32')\n",
        "\n",
        "    for i in range(n_r):\n",
        "        u_id = data[idx[i], 0]\n",
        "        m_id = data[idx[i], 1]\n",
        "        r = data[idx[i], 2]\n",
        "\n",
        "        if i < int(frac * n_r):\n",
        "            test_r[mdict[m_id], udict[u_id]] = r\n",
        "        else:\n",
        "            train_r[mdict[m_id], udict[u_id]] = r\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_r - int(frac * n_r)))\n",
        "    print('num of test ratings: {}'.format(int(frac * n_r)))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "7rMjcbLvhtRs"
      },
      "outputs": [],
      "source": [
        "def load_matlab_file(path_file, name_field):\n",
        "    \n",
        "    db = h5py.File(path_file, 'r')\n",
        "    ds = db[name_field]\n",
        "\n",
        "    try:\n",
        "        if 'ir' in ds.keys():\n",
        "            data = np.asarray(ds['data'])\n",
        "            ir   = np.asarray(ds['ir'])\n",
        "            jc   = np.asarray(ds['jc'])\n",
        "            out  = csc_matrix((data, ir, jc)).astype(np.float32)\n",
        "    except AttributeError:\n",
        "        out = np.asarray(ds).astype(np.float32).T\n",
        "\n",
        "    db.close()\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "g6pIUrkza2zv"
      },
      "outputs": [],
      "source": [
        "def load_data_monti(path='./'):\n",
        "\n",
        "    M = load_matlab_file(path+'douban_monti_dataset.mat', 'M')\n",
        "    Otraining = load_matlab_file(path+'douban_monti_dataset.mat', 'Otraining') * M\n",
        "    Otest = load_matlab_file(path+'douban_monti_dataset.mat', 'Otest') * M\n",
        "\n",
        "    n_u = M.shape[0]  # num of users\n",
        "    n_m = M.shape[1]  # num of movies\n",
        "    n_train = Otraining[np.where(Otraining)].size  # num of training ratings\n",
        "    n_test = Otest[np.where(Otest)].size  # num of test ratings\n",
        "\n",
        "    train_r = Otraining.T\n",
        "    test_r = Otest.T\n",
        "\n",
        "    train_m = np.greater(train_r, 1e-12).astype('float32')  # masks indicating non-zero entries\n",
        "    test_m = np.greater(test_r, 1e-12).astype('float32')\n",
        "\n",
        "    print('data matrix loaded')\n",
        "    print('num of users: {}'.format(n_u))\n",
        "    print('num of movies: {}'.format(n_m))\n",
        "    print('num of training ratings: {}'.format(n_train))\n",
        "    print('num of test ratings: {}'.format(n_test))\n",
        "\n",
        "    return n_m, n_u, train_r, train_m, test_r, test_m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_8kEkg9mlIW"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "0fkA1WpmipzF"
      },
      "outputs": [],
      "source": [
        "# Insert the path of a data directory by yourself (e.g., '/content/.../data')\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
        "data_path = '../../data'\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "ijlu0lXQioYM"
      },
      "outputs": [],
      "source": [
        "# Select a dataset among 'ML-1M', 'ML-100K', and 'Douban'\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
        "dataset = 'ML-1M'\n",
        "# .-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "sJqSSY33mgkw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading data...\n",
            "taken 6.043224573135376 seconds\n",
            "data matrix loaded\n",
            "num of users: 6040\n",
            "num of movies: 3706\n",
            "num of training ratings: 900189\n",
            "num of test ratings: 100020\n"
          ]
        }
      ],
      "source": [
        "# Data Load\n",
        "try:\n",
        "    if dataset == 'ML-100K':\n",
        "        path = data_path + '/MovieLens_100K/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_100k(path=path, delimiter='\\t')\n",
        "\n",
        "    elif dataset == 'ML-1M':\n",
        "        path = data_path + '/ml-1m/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_1m(path=path, delimiter='::', frac=0.1, seed=1234)\n",
        "\n",
        "    elif dataset == 'Douban':\n",
        "        path = data_path + '/Douban_monti/'\n",
        "        n_m, n_u, train_r, train_m, test_r, test_m = load_data_monti(path=path)\n",
        "\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "except ValueError:\n",
        "    print('Error: Unable to load data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQMtA9yml-gp"
      },
      "source": [
        "# Hyperparameter Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "nGCdp_FlobOK"
      },
      "outputs": [],
      "source": [
        "# Common hyperparameter settings\n",
        "n_hid = 500\n",
        "n_dim = 5\n",
        "n_layers = 2\n",
        "gk_size = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "344bwGB0cWXp"
      },
      "outputs": [],
      "source": [
        "# Different hyperparameter settings for each dataset\n",
        "if dataset == 'ML-100K':\n",
        "    lambda_2 = 20.  # l2 regularisation\n",
        "    lambda_s = 0.006\n",
        "    iter_p = 5  # optimisation\n",
        "    iter_f = 5\n",
        "    epoch_p = 30  # training epoch\n",
        "    epoch_f = 60\n",
        "    dot_scale = 1  # scaled dot product\n",
        "\n",
        "elif dataset == 'ML-1M':\n",
        "    lambda_2 = 70.\n",
        "    lambda_s = 0.018\n",
        "    iter_p = 50\n",
        "    iter_f = 10\n",
        "    epoch_p = 20\n",
        "    epoch_f = 30\n",
        "    dot_scale = 0.5\n",
        "\n",
        "elif dataset == 'Douban':\n",
        "    lambda_2 = 10.\n",
        "    lambda_s = 0.022\n",
        "    iter_p = 5\n",
        "    iter_f = 5\n",
        "    epoch_p = 20\n",
        "    epoch_f = 60\n",
        "    dot_scale = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "b94aimX3nAMI"
      },
      "outputs": [],
      "source": [
        "R = tf.placeholder(\"float\", [n_m, n_u])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sWtU4-pmDDT"
      },
      "source": [
        "# Network Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "wX2wREO09zde"
      },
      "outputs": [],
      "source": [
        "def local_kernel(u, v):\n",
        "\n",
        "    dist = tf.norm(u - v, ord=2, axis=2)\n",
        "    hat = tf.maximum(0., 1. - dist**2)\n",
        "\n",
        "    return hat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "c88l9LYr9175"
      },
      "outputs": [],
      "source": [
        "def kernel_layer(x, n_hid=n_hid, n_dim=n_dim, activation=tf.nn.sigmoid, lambda_s=lambda_s, lambda_2=lambda_2, name=''):\n",
        "\n",
        "    with tf.variable_scope(name, reuse=tf.AUTO_REUSE):\n",
        "        W = tf.get_variable('W', [x.shape[1], n_hid])\n",
        "        n_in = x.get_shape().as_list()[1]\n",
        "        u = tf.get_variable('u', initializer=tf.random.truncated_normal([n_in, 1, n_dim], 0., 1e-3))\n",
        "        v = tf.get_variable('v', initializer=tf.random.truncated_normal([1, n_hid, n_dim], 0., 1e-3))\n",
        "        b = tf.get_variable('b', [n_hid])\n",
        "\n",
        "    w_hat = local_kernel(u, v)\n",
        "    \n",
        "    sparse_reg = tf.contrib.layers.l2_regularizer(lambda_s)\n",
        "    sparse_reg_term = tf.contrib.layers.apply_regularization(sparse_reg, [w_hat])\n",
        "    \n",
        "    l2_reg = tf.contrib.layers.l2_regularizer(lambda_2)\n",
        "    l2_reg_term = tf.contrib.layers.apply_regularization(l2_reg, [W])\n",
        "\n",
        "    W_eff = W * w_hat  # Local kernelised weight matrix\n",
        "    y = tf.matmul(x, W_eff) + b\n",
        "    y = activation(y)\n",
        "\n",
        "    return y, sparse_reg_term + l2_reg_term"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "rlb95FmRVATa"
      },
      "outputs": [],
      "source": [
        "def global_kernel(input, gk_size, dot_scale):\n",
        "\n",
        "    avg_pooling = tf.reduce_mean(input, axis=1)  # Item (axis=1) based average pooling\n",
        "    avg_pooling = tf.reshape(avg_pooling, [1, -1])\n",
        "    n_kernel = avg_pooling.shape[1].value\n",
        "\n",
        "    conv_kernel = tf.get_variable('conv_kernel', initializer=tf.random.truncated_normal([n_kernel, gk_size**2], stddev=0.1))\n",
        "    gk = tf.matmul(avg_pooling, conv_kernel) * dot_scale  # Scaled dot product\n",
        "    gk = tf.reshape(gk, [gk_size, gk_size, 1, 1])\n",
        "\n",
        "    return gk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "jTLi_65XzIbH"
      },
      "outputs": [],
      "source": [
        "def global_conv(input, W):\n",
        "\n",
        "    input = tf.reshape(input, [1, input.shape[0], input.shape[1], 1])\n",
        "    conv2d = tf.nn.relu(tf.nn.conv2d(input, W, strides=[1,1,1,1], padding='SAME'))\n",
        "\n",
        "    return tf.reshape(conv2d, [conv2d.shape[1], conv2d.shape[2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8sQCwrSmKG4"
      },
      "source": [
        "# Network Instantiation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOtWj1SCo1RW"
      },
      "source": [
        "## Pre-training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "7teUrgWagpW0"
      },
      "outputs": [],
      "source": [
        "y = R\n",
        "reg_losses = None\n",
        "\n",
        "for i in range(n_layers):\n",
        "    y, reg_loss = kernel_layer(y, name=str(i))\n",
        "    reg_losses = reg_loss if reg_losses is None else reg_losses + reg_loss\n",
        "\n",
        "pred_p, reg_loss = kernel_layer(y, n_u, activation=tf.identity, name='out')\n",
        "reg_losses = reg_losses + reg_loss\n",
        "\n",
        "# L2 loss\n",
        "diff = train_m * (train_r - pred_p)\n",
        "sqE = tf.nn.l2_loss(diff)\n",
        "loss_p = sqE + reg_losses\n",
        "\n",
        "optimizer_p = tf.contrib.opt.ScipyOptimizerInterface(loss_p, options={'disp': True, 'maxiter': iter_p, 'maxcor': 10}, method='L-BFGS-B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IEBsNhNo4Cj"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "OiTXqnN6zLXQ"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Variable conv_kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"c:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"c:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"c:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"c:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-49-f9ef409f13c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_dash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernel_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_u\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'out'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mgk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglobal_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_dash\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdot_scale\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Global kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mglobal_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgk\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Global kernel-based rating matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<ipython-input-46-af8e54afc75f>\u001b[0m in \u001b[0;36mglobal_kernel\u001b[1;34m(input, gk_size, dot_scale)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mn_kernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_pooling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mconv_kernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'conv_kernel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruncated_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_kernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgk_size\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mgk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mavg_pooling\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv_kernel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mdot_scale\u001b[0m  \u001b[1;31m# Scaled dot product\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mgk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mgk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1498\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1499\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1500\u001b[1;33m       aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m   1241\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1242\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1243\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m   1244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[1;32mc:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    565\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m   def _get_partitioned_variable(self,\n",
            "\u001b[1;32mc:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    517\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m           aggregation=aggregation)\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     synchronization, aggregation, trainable = (\n",
            "\u001b[1;32mc:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[0;32m    866\u001b[0m         \u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtb\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"tensorflow/python\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         raise ValueError(\"%s Originally defined at:\\n\\n%s\" %\n\u001b[1;32m--> 868\u001b[1;33m                          (err_msg, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    869\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: Variable conv_kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"c:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\n    self._traceback = tf_stack.extract_stack()\n  File \"c:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\n    op_def=op_def)\n  File \"c:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\n    attrs, op_def, compute_device)\n  File \"c:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"c:\\Users\\Komi\\Papers\\RS-BIAS\\SUB-COFI\\venvGLOCAL_K\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\n    op_def=op_def)\n"
          ]
        }
      ],
      "source": [
        "y = R\n",
        "reg_losses = None\n",
        "\n",
        "for i in range(n_layers):\n",
        "    y, _ = kernel_layer(y, name=str(i))\n",
        "\n",
        "y_dash, _ = kernel_layer(y, n_u, activation=tf.identity, name='out')\n",
        "\n",
        "gk = global_kernel(y_dash, gk_size, dot_scale)  # Global kernel\n",
        "y_hat = global_conv(train_r, gk)  # Global kernel-based rating matrix\n",
        "\n",
        "for i in range(n_layers):\n",
        "    y_hat, reg_loss = kernel_layer(y_hat, name=str(i))\n",
        "    reg_losses = reg_loss if reg_losses is None else reg_losses + reg_loss\n",
        "\n",
        "pred_f, reg_loss = kernel_layer(y_hat, n_u, activation=tf.identity, name='out')\n",
        "reg_losses = reg_losses + reg_loss\n",
        "\n",
        "# L2 loss\n",
        "diff = train_m * (train_r - pred_f)\n",
        "sqE = tf.nn.l2_loss(diff)\n",
        "loss_f = sqE + reg_losses\n",
        "\n",
        "optimizer_f = tf.contrib.opt.ScipyOptimizerInterface(loss_f, options={'disp': True, 'maxiter': iter_f, 'maxcor': 10}, method='L-BFGS-B')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sETwz58aK6y6"
      },
      "source": [
        "# Evaluation code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyReXxgac3KH"
      },
      "outputs": [],
      "source": [
        "def dcg_k(score_label, k):\n",
        "    dcg, i = 0., 0\n",
        "    for s in score_label:\n",
        "        if i < k:\n",
        "            dcg += (2**s[1]-1) / np.log2(2+i)\n",
        "            i += 1\n",
        "    return dcg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwsSR-8ZdGWo"
      },
      "outputs": [],
      "source": [
        "def ndcg_k(y_hat, y, k):\n",
        "    score_label = np.stack([y_hat, y], axis=1).tolist()\n",
        "    score_label = sorted(score_label, key=lambda d:d[0], reverse=True)\n",
        "    score_label_ = sorted(score_label, key=lambda d:d[1], reverse=True)\n",
        "    norm, i = 0., 0\n",
        "    for s in score_label_:\n",
        "        if i < k:\n",
        "            norm += (2**s[1]-1) / np.log2(2+i)\n",
        "            i += 1\n",
        "    dcg = dcg_k(score_label, k)\n",
        "    return dcg / norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yy9eQS51pbhj"
      },
      "outputs": [],
      "source": [
        "def call_ndcg(y_hat, y):\n",
        "    ndcg_sum, num = 0, 0\n",
        "    y_hat, y = y_hat.T, y.T\n",
        "    n_users = y.shape[0]\n",
        "\n",
        "    for i in range(n_users):\n",
        "        y_hat_i = y_hat[i][np.where(y[i])]\n",
        "        y_i = y[i][np.where(y[i])]\n",
        "\n",
        "        if y_i.shape[0] < 2:\n",
        "            continue\n",
        "\n",
        "        ndcg_sum += ndcg_k(y_hat_i, y_i, y_i.shape[0])  # user-wise calculation\n",
        "        num += 1\n",
        "\n",
        "    return ndcg_sum / num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXXQjeMxmYEC"
      },
      "source": [
        "# Training and Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtain the train and test samples in a Pandas DataFrame\n",
        "# with format user_id (int), movie_id (int), rating (float)\n",
        "# and save them as CSV files\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def extract_test_samples(rating_matrix, mask_matrix):\n",
        "    test_samples = np.where(mask_matrix > 0)\n",
        "    test_samples = np.stack([test_samples[1], test_samples[0]], axis=1)\n",
        "    test_samples = pd.DataFrame(test_samples, columns=['user_id', 'movie_id'])\n",
        "    test_samples['rating'] = rating_matrix[test_samples['movie_id'], test_samples['user_id']]\n",
        "\n",
        "    return test_samples\n",
        "\n",
        "train_samples = extract_test_samples(train_r, train_m)\n",
        "test_samples = extract_test_samples(test_r, test_m)\n",
        "\n",
        "OUTPUTS_PATH = '../../outputs/'\n",
        "MODEL_NAME = 'GLOCAL_K'\n",
        "\n",
        "# Make sure that the directory exists\n",
        "import os\n",
        "os.makedirs(OUTPUTS_PATH + MODEL_NAME, exist_ok=True)\n",
        "\n",
        "\n",
        "train_samples.to_csv(OUTPUTS_PATH + MODEL_NAME + '/train_samples.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ35Zoha-Eue"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU available: True\n",
            "GPU device: /device:GPU:0\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 458750.125000\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 54\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 1 test rmse: 0.8875202 train rmse: 0.8721349\n",
            "Time: 49.27401328086853 seconds\n",
            "Time cumulative: 49.27401328086853 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 396779.750000\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 55\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 2 test rmse: 0.8537257 train rmse: 0.8172088\n",
            "Time: 40.6120867729187 seconds\n",
            "Time cumulative: 89.88610005378723 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 372244.593750\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 53\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 3 test rmse: 0.8401559 train rmse: 0.78682417\n",
            "Time: 40.24931764602661 seconds\n",
            "Time cumulative: 130.13541769981384 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 361045.406250\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 54\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 4 test rmse: 0.83446664 train rmse: 0.76617277\n",
            "Time: 40.968323945999146 seconds\n",
            "Time cumulative: 171.103741645813 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 348462.562500\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 54\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 5 test rmse: 0.8323697 train rmse: 0.7574792\n",
            "Time: 40.07125377655029 seconds\n",
            "Time cumulative: 211.17499542236328 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 342983.093750\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 53\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 6 test rmse: 0.8300738 train rmse: 0.75165576\n",
            "Time: 40.623274087905884 seconds\n",
            "Time cumulative: 251.79826951026917 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 340615.437500\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 54\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 7 test rmse: 0.8283963 train rmse: 0.74415827\n",
            "Time: 40.322046518325806 seconds\n",
            "Time cumulative: 292.12031602859497 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 339063.187500\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 55\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 8 test rmse: 0.82735914 train rmse: 0.74013054\n",
            "Time: 39.97853136062622 seconds\n",
            "Time cumulative: 332.0988473892212 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 337882.781250\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 54\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 9 test rmse: 0.82649606 train rmse: 0.7364417\n",
            "Time: 40.478012800216675 seconds\n",
            "Time cumulative: 372.57686018943787 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 336737.343750\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 54\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 10 test rmse: 0.8257223 train rmse: 0.73278207\n",
            "Time: 40.11157274246216 seconds\n",
            "Time cumulative: 412.6884329319 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 335561.375000\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 53\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 11 test rmse: 0.8250182 train rmse: 0.7298369\n",
            "Time: 40.6740620136261 seconds\n",
            "Time cumulative: 453.3624949455261 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 334351.562500\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 53\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 12 test rmse: 0.82452255 train rmse: 0.72730786\n",
            "Time: 40.54749369621277 seconds\n",
            "Time cumulative: 493.9099886417389 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 333044.343750\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 53\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 13 test rmse: 0.8241522 train rmse: 0.7255389\n",
            "Time: 40.148929595947266 seconds\n",
            "Time cumulative: 534.0589182376862 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 331585.812500\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 54\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 14 test rmse: 0.8241823 train rmse: 0.7236615\n",
            "Time: 39.997493743896484 seconds\n",
            "Time cumulative: 574.0564119815826 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 329979.250000\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 54\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 15 test rmse: 0.823619 train rmse: 0.7216414\n",
            "Time: 40.913411140441895 seconds\n",
            "Time cumulative: 614.9698231220245 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 328727.687500\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 54\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 16 test rmse: 0.82351905 train rmse: 0.71980524\n",
            "Time: 40.38797116279602 seconds\n",
            "Time cumulative: 655.3577942848206 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 327709.250000\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 53\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 17 test rmse: 0.82344675 train rmse: 0.7181423\n",
            "Time: 40.66240739822388 seconds\n",
            "Time cumulative: 696.0202016830444 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 326925.375000\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 54\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 18 test rmse: 0.82332784 train rmse: 0.716388\n",
            "Time: 40.152328968048096 seconds\n",
            "Time cumulative: 736.1725306510925 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 326284.593750\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 54\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 19 test rmse: 0.8233315 train rmse: 0.71516687\n",
            "Time: 40.12280797958374 seconds\n",
            "Time cumulative: 776.2953386306763 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 325723.875000\n",
            "  Number of iterations: 50\n",
            "  Number of functions evaluations: 53\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "PRE-TRAINING\n",
            "Epoch: 20 test rmse: 0.82341075 train rmse: 0.71341723\n",
            "Time: 39.43523955345154 seconds\n",
            "Time cumulative: 815.7305781841278 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 328597.593750\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 11\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 1 test rmse: 0.8333989 test mae: 0.6493531 test ndcg: 0.9267309711030658\n",
            "Epoch: 1 train rmse: 0.71751964 train mae: 0.56087554 train ndcg: 0.9639299811102935\n",
            "Time: 24.640892505645752 seconds\n",
            "Time cumulative: 840.3714706897736 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 321707.656250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 2 test rmse: 0.82773197 test mae: 0.6446464 test ndcg: 0.9278472321771276\n",
            "Epoch: 2 train rmse: 0.7075675 train mae: 0.55330473 train ndcg: 0.9648874436715678\n",
            "Time: 11.39855146408081 seconds\n",
            "Time cumulative: 851.7700221538544 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 318824.656250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 3 test rmse: 0.82567716 test mae: 0.64335954 test ndcg: 0.928296210460926\n",
            "Epoch: 3 train rmse: 0.70420235 train mae: 0.5510154 train ndcg: 0.9654020962230601\n",
            "Time: 11.946775197982788 seconds\n",
            "Time cumulative: 863.7167973518372 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 317130.906250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 4 test rmse: 0.82520044 test mae: 0.64324 test ndcg: 0.9283289306386668\n",
            "Epoch: 4 train rmse: 0.7023658 train mae: 0.549995 train ndcg: 0.9655716031608108\n",
            "Time: 12.131168365478516 seconds\n",
            "Time cumulative: 875.8479657173157 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 315707.343750\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 5 test rmse: 0.8244664 test mae: 0.64263016 test ndcg: 0.9285500220341079\n",
            "Epoch: 5 train rmse: 0.7010603 train mae: 0.54897916 train ndcg: 0.9656268033603167\n",
            "Time: 11.510862350463867 seconds\n",
            "Time cumulative: 887.3588280677795 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 314618.218750\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 6 test rmse: 0.82407266 test mae: 0.6420861 test ndcg: 0.9284517403887356\n",
            "Epoch: 6 train rmse: 0.6999521 train mae: 0.5478579 train ndcg: 0.9657889794433422\n",
            "Time: 11.873706579208374 seconds\n",
            "Time cumulative: 899.2325346469879 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 313717.250000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 7 test rmse: 0.82387936 test mae: 0.64233595 test ndcg: 0.9285453119409334\n",
            "Epoch: 7 train rmse: 0.6994919 train mae: 0.547961 train ndcg: 0.9659739266847708\n",
            "Time: 12.129135608673096 seconds\n",
            "Time cumulative: 911.361670255661 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 312903.406250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 8 test rmse: 0.8238753 test mae: 0.64226514 test ndcg: 0.9289503530545149\n",
            "Epoch: 8 train rmse: 0.69885856 train mae: 0.5474579 train ndcg: 0.9659436971850313\n",
            "Time: 11.550428867340088 seconds\n",
            "Time cumulative: 922.9120991230011 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 312169.937500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 9 test rmse: 0.82369274 test mae: 0.6421716 test ndcg: 0.9288981914258229\n",
            "Epoch: 9 train rmse: 0.6983581 train mae: 0.5471037 train ndcg: 0.9661113353875722\n",
            "Time: 12.112271308898926 seconds\n",
            "Time cumulative: 935.0243704319 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 311274.250000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 10 test rmse: 0.8237243 test mae: 0.6423192 test ndcg: 0.9286789003756937\n",
            "Epoch: 10 train rmse: 0.69808275 train mae: 0.54698515 train ndcg: 0.9661641090706625\n",
            "Time: 12.111387729644775 seconds\n",
            "Time cumulative: 947.1357581615448 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 310518.656250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 11 test rmse: 0.823292 test mae: 0.6418669 test ndcg: 0.9285815260523871\n",
            "Epoch: 11 train rmse: 0.6973807 train mae: 0.5463359 train ndcg: 0.9662179296421146\n",
            "Time: 11.676629066467285 seconds\n",
            "Time cumulative: 958.8123872280121 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 309795.750000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 12 test rmse: 0.8235597 test mae: 0.6422321 test ndcg: 0.928633188702556\n",
            "Epoch: 12 train rmse: 0.6969873 train mae: 0.5462401 train ndcg: 0.9662649827675406\n",
            "Time: 12.174107074737549 seconds\n",
            "Time cumulative: 970.9864943027496 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 309205.093750\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 13 test rmse: 0.8234682 test mae: 0.64205605 test ndcg: 0.9287639758538336\n",
            "Epoch: 13 train rmse: 0.69656765 train mae: 0.545812 train ndcg: 0.9662834183162287\n",
            "Time: 12.133626461029053 seconds\n",
            "Time cumulative: 983.1201207637787 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 308560.875000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 14 test rmse: 0.82340217 test mae: 0.6421472 test ndcg: 0.928696887596482\n",
            "Epoch: 14 train rmse: 0.69614327 train mae: 0.54563695 train ndcg: 0.9663329089241097\n",
            "Time: 11.720314502716064 seconds\n",
            "Time cumulative: 994.8404352664948 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 308005.750000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 15 test rmse: 0.8233122 test mae: 0.6419333 test ndcg: 0.9287089693413443\n",
            "Epoch: 15 train rmse: 0.6958393 train mae: 0.5452639 train ndcg: 0.9663733814505129\n",
            "Time: 11.933890581130981 seconds\n",
            "Time cumulative: 1006.7743258476257 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 307529.500000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 16 test rmse: 0.8232829 test mae: 0.6419974 test ndcg: 0.9287577569364365\n",
            "Epoch: 16 train rmse: 0.6954869 train mae: 0.5450583 train ndcg: 0.9664098962973368\n",
            "Time: 12.142587184906006 seconds\n",
            "Time cumulative: 1018.9169130325317 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 307109.250000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 17 test rmse: 0.82334125 test mae: 0.6419336 test ndcg: 0.9286992681669868\n",
            "Epoch: 17 train rmse: 0.69524753 train mae: 0.54482126 train ndcg: 0.9664699256468156\n",
            "Time: 11.55045223236084 seconds\n",
            "Time cumulative: 1030.4673652648926 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 306730.625000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 18 test rmse: 0.8232849 test mae: 0.6419414 test ndcg: 0.9287677950377613\n",
            "Epoch: 18 train rmse: 0.694918 train mae: 0.54459476 train ndcg: 0.9664721422242873\n",
            "Time: 11.970296621322632 seconds\n",
            "Time cumulative: 1042.4376618862152 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 306432.250000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 14\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 19 test rmse: 0.8232071 test mae: 0.6418057 test ndcg: 0.9286464616758096\n",
            "Epoch: 19 train rmse: 0.69469774 train mae: 0.5443965 train ndcg: 0.9665292615147973\n",
            "Time: 12.57857871055603 seconds\n",
            "Time cumulative: 1055.0162405967712 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 306115.812500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 20 test rmse: 0.82327235 test mae: 0.64199674 test ndcg: 0.9285556751022742\n",
            "Epoch: 20 train rmse: 0.6945161 train mae: 0.544346 train ndcg: 0.9665738682571636\n",
            "Time: 11.744111061096191 seconds\n",
            "Time cumulative: 1066.7603516578674 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 305748.687500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 21 test rmse: 0.8233247 test mae: 0.64195055 test ndcg: 0.9288168718763664\n",
            "Epoch: 21 train rmse: 0.694236 train mae: 0.5440906 train ndcg: 0.9666179567545345\n",
            "Time: 12.168063163757324 seconds\n",
            "Time cumulative: 1078.9284148216248 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 305525.093750\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 15\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 22 test rmse: 0.8232229 test mae: 0.6418208 test ndcg: 0.9287638422582152\n",
            "Epoch: 22 train rmse: 0.69402117 train mae: 0.5438735 train ndcg: 0.9666241995021541\n",
            "Time: 12.62148904800415 seconds\n",
            "Time cumulative: 1091.549903869629 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 305122.500000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 23 test rmse: 0.8232364 test mae: 0.641759 test ndcg: 0.9286388418683227\n",
            "Epoch: 23 train rmse: 0.6938134 train mae: 0.5436957 train ndcg: 0.9666822925688431\n",
            "Time: 11.697084665298462 seconds\n",
            "Time cumulative: 1103.2469885349274 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 304842.375000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 24 test rmse: 0.8233831 test mae: 0.6419931 test ndcg: 0.9287589356772825\n",
            "Epoch: 24 train rmse: 0.6935375 train mae: 0.54356533 train ndcg: 0.9666606866140884\n",
            "Time: 12.091423749923706 seconds\n",
            "Time cumulative: 1115.338412284851 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 304572.625000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 12\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 25 test rmse: 0.8234209 test mae: 0.6419068 test ndcg: 0.9286634696860484\n",
            "Epoch: 25 train rmse: 0.6933756 train mae: 0.54336935 train ndcg: 0.9666915630277111\n",
            "Time: 12.161927461624146 seconds\n",
            "Time cumulative: 1127.5003397464752 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 304313.562500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 26 test rmse: 0.82330275 test mae: 0.641911 test ndcg: 0.9287129764256719\n",
            "Epoch: 26 train rmse: 0.6931107 train mae: 0.54318625 train ndcg: 0.9667054683481909\n",
            "Time: 11.676553010940552 seconds\n",
            "Time cumulative: 1139.1768927574158 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 304102.375000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 27 test rmse: 0.8233902 test mae: 0.64192754 test ndcg: 0.9286209280357697\n",
            "Epoch: 27 train rmse: 0.6929711 train mae: 0.5430965 train ndcg: 0.9667428317510357\n",
            "Time: 12.073315382003784 seconds\n",
            "Time cumulative: 1151.2502081394196 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 303863.156250\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 28 test rmse: 0.8233269 test mae: 0.64190567 test ndcg: 0.9286663987200934\n",
            "Epoch: 28 train rmse: 0.6927501 train mae: 0.54291123 train ndcg: 0.9667645010171239\n",
            "Time: 12.267271280288696 seconds\n",
            "Time cumulative: 1163.5174794197083 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 303632.687500\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 13\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 29 test rmse: 0.82333225 test mae: 0.6418405 test ndcg: 0.9286490588684506\n",
            "Epoch: 29 train rmse: 0.69256395 train mae: 0.54273164 train ndcg: 0.9667786720391441\n",
            "Time: 11.73072600364685 seconds\n",
            "Time cumulative: 1175.248205423355 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "INFO:tensorflow:Optimization terminated with:\n",
            "  Message: b'STOP: TOTAL NO. of ITERATIONS REACHED LIMIT'\n",
            "  Objective function value: 303449.500000\n",
            "  Number of iterations: 10\n",
            "  Number of functions evaluations: 15\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "FINE-TUNING\n",
            "Epoch: 30 test rmse: 0.8233477 test mae: 0.6419624 test ndcg: 0.9287122511004124\n",
            "Epoch: 30 train rmse: 0.69236845 train mae: 0.5426534 train ndcg: 0.9668086606486282\n",
            "Time: 12.50417423248291 seconds\n",
            "Time cumulative: 1187.752379655838 seconds\n",
            ".-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._.-^-._\n",
            "Best test rmse: 0.8232071 at epoch 19\n"
          ]
        }
      ],
      "source": [
        "best_rmse_ep, best_mae_ep, best_ndcg_ep = 0, 0, 0\n",
        "best_rmse, best_mae, best_ndcg = float(\"inf\"), float(\"inf\"), 0\n",
        "\n",
        "time_cumulative = 0\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Check GPU is available\n",
        "\n",
        "print('GPU available:', tf.test.is_gpu_available())\n",
        "print('GPU device:', tf.test.gpu_device_name())\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(epoch_p):\n",
        "        tic = time()\n",
        "        optimizer_p.minimize(sess, feed_dict={R: train_r})\n",
        "        pre = sess.run(pred_p, feed_dict={R: train_r})\n",
        "\n",
        "        t = time() - tic\n",
        "        time_cumulative += t\n",
        "        \n",
        "        error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n",
        "        test_rmse = np.sqrt(error)\n",
        "\n",
        "        error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n",
        "        train_rmse = np.sqrt(error_train)\n",
        "\n",
        "        print('.-^-._' * 12)\n",
        "        print('PRE-TRAINING')\n",
        "        print('Epoch:', i+1, 'test rmse:', test_rmse, 'train rmse:', train_rmse)\n",
        "        print('Time:', t, 'seconds')\n",
        "        print('Time cumulative:', time_cumulative, 'seconds')\n",
        "        print('.-^-._' * 12)\n",
        "\n",
        "    for i in range(epoch_f):\n",
        "        tic = time()\n",
        "        optimizer_f.minimize(sess, feed_dict={R: train_r})\n",
        "        pre = sess.run(pred_f, feed_dict={R: train_r})\n",
        "\n",
        "        t = time() - tic\n",
        "        time_cumulative += t\n",
        "        \n",
        "        error = (test_m * (np.clip(pre, 1., 5.) - test_r) ** 2).sum() / test_m.sum()  # test error\n",
        "        test_rmse = np.sqrt(error)\n",
        "\n",
        "        error_train = (train_m * (np.clip(pre, 1., 5.) - train_r) ** 2).sum() / train_m.sum()  # train error\n",
        "        train_rmse = np.sqrt(error_train)\n",
        "\n",
        "        test_mae = (test_m * np.abs(np.clip(pre, 1., 5.) - test_r)).sum() / test_m.sum()\n",
        "        train_mae = (train_m * np.abs(np.clip(pre, 1., 5.) - train_r)).sum() / train_m.sum()\n",
        "\n",
        "        test_ndcg = call_ndcg(np.clip(pre, 1., 5.), test_r)\n",
        "        train_ndcg = call_ndcg(np.clip(pre, 1., 5.), train_r)\n",
        "\n",
        "        if test_rmse < best_rmse:\n",
        "            best_rmse = test_rmse\n",
        "            best_rmse_ep = i+1\n",
        "\n",
        "            # Update predictions in the dataframe\n",
        "            test_samples['pred'] = np.clip(pre[test_samples['movie_id'], test_samples['user_id']], 1., 5.)\n",
        "        \n",
        "        if test_mae < best_mae:\n",
        "            best_mae = test_mae\n",
        "            best_mae_ep = i+1\n",
        "\n",
        "        if best_ndcg < test_ndcg:\n",
        "            best_ndcg = test_ndcg\n",
        "            best_ndcg_ep = i+1\n",
        "\n",
        "        print('.-^-._' * 12)\n",
        "        print('FINE-TUNING')\n",
        "        print('Epoch:', i+1, 'test rmse:', test_rmse, 'test mae:', test_mae, 'test ndcg:', test_ndcg)\n",
        "        print('Epoch:', i+1, 'train rmse:', train_rmse, 'train mae:', train_mae, 'train ndcg:', train_ndcg)\n",
        "        print('Time:', t, 'seconds')\n",
        "        print('Time cumulative:', time_cumulative, 'seconds')\n",
        "        print('.-^-._' * 12)\n",
        "\n",
        "    print('Best test rmse:', best_rmse, 'at epoch', best_rmse_ep)\n",
        "\n",
        "    # Save the predictions in a CSV file\n",
        "    test_samples.to_csv(OUTPUTS_PATH + MODEL_NAME + '/test_samples_with_predictions.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTi_PdXJqTjh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 19  best rmse: 0.8232071\n",
            "Epoch: 23  best mae: 0.641759\n",
            "Epoch: 8  best ndcg: 0.9289503530545149\n"
          ]
        }
      ],
      "source": [
        "# Final result\n",
        "print('Epoch:', best_rmse_ep, ' best rmse:', best_rmse)\n",
        "print('Epoch:', best_mae_ep, ' best mae:', best_mae)\n",
        "print('Epoch:', best_ndcg_ep, ' best ndcg:', best_ndcg)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "GLocal_K.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
